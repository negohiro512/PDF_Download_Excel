import streamlit as st
import os
import time
import urllib.parse
import requests
import shutil
import tempfile
import json
import pandas as pd
from bs4 import BeautifulSoup
import google.generativeai as genai
import datetime

# --- ç”»é¢è¨­å®š ---
st.set_page_config(page_title="PDFä¸€æ‹¬DL & AIæŠ½å‡º", layout="wide")

st.title("ğŸ“„ PDFä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼ & AIå°å¸³ä½œæˆ")
st.markdown("""
æŒ‡å®šURLã‹ã‚‰PDFã‚’åé›†ã—ã€**å‰å¹´åº¦å®Ÿç¸¾ï¼ˆå ±å‘Šæ›¸æƒ…å ±ï¼‰**ã®æ•°å€¤ã‚’æŠ½å‡ºã—ã¦ExcelåŒ–ã—ã¾ã™ã€‚
å®Ÿè¡Œçµæœã¯ç”»é¢ä¸‹ã®ã€Œå®Ÿè¡Œå±¥æ­´ã€ã«ä¿å­˜ã•ã‚Œã€**ã¾ã¨ã‚ã¦çµåˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**ã‚‚å¯èƒ½ã§ã™ã€‚
""")

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆï¼ˆå±¥æ­´ä¿å­˜ç”¨ï¼‰ã®åˆæœŸåŒ– ---
if 'history' not in st.session_state:
    st.session_state['history'] = []

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šè¨­å®š ---
with st.sidebar:
    st.header("è¨­å®š")
    
    # 1. ã¾ãšSecretsï¼ˆå®‰å…¨ãªä¿ç®¡å ´æ‰€ï¼‰ã‹ã‚‰ã‚­ãƒ¼ã‚’æ¢ã™
    if "GEMINI_API_KEY" in st.secrets:
        api_key = st.secrets["GEMINI_API_KEY"]
        st.success("ğŸ”‘ APIã‚­ãƒ¼ã‚’è‡ªå‹•ã§èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    # 2. ãªã‘ã‚Œã°å…¥åŠ›æ¬„ã‚’è¡¨ç¤ºã™ã‚‹ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã‚„æœªè¨­å®šæ™‚ç”¨ï¼‰
    else:
        api_key = st.text_input("Gemini APIã‚­ãƒ¼", type="password", help="Google AI Studioã§å–å¾—ã—ãŸã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

    debug_mode = st.checkbox("ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ï¼ˆã‚¨ãƒ©ãƒ¼è©³ç´°ã‚’è¡¨ç¤ºï¼‰")
    
    # å±¥æ­´ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
    if st.button("ğŸ—‘ï¸ å±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
        st.session_state['history'] = []
        st.rerun()

    if api_key:
        genai.configure(api_key=api_key)
    st.info("â€»APIã‚­ãƒ¼ãŒãªã„å ´åˆã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã®ã¿å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚")
# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›æ¬„ ---
col1, col2 = st.columns([2, 1])
with col1:
    default_url = "https://www.city.fukuoka.lg.jp/kankyo/sanhai/hp/sangyouhaikibutu/haisyutujigyousya/taryoukouhyou.html"
    target_url = st.text_input("å¯¾è±¡ã®URL", default_url)
with col2:
    keyword = st.text_input("ãƒ•ã‚¡ã‚¤ãƒ«åã«å«ã‚€æ–‡å­—", "06")

# --- é–¢æ•°ï¼šPDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ---
def download_pdfs(target_url, keyword, save_dir, status_text, progress_bar):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
        "Accept-Language": "ja,en-US;q=0.9,en;q=0.8",
        "Referer": "https://www.google.com/"
    }
    
    status_text.text("ã‚µã‚¤ãƒˆã®æƒ…å ±ã‚’å–å¾—ä¸­...")
    try:
        response = requests.get(target_url, headers=headers, timeout=10)
        response.raise_for_status()
    except Exception as e:
        st.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return []
    
    response.encoding = response.apparent_encoding
    soup = BeautifulSoup(response.content, "html.parser")
    links = soup.find_all("a")
    
    download_targets = []
    for link in links:
        href = link.get("href")
        if href and href.lower().endswith(".pdf"):
            full_url = urllib.parse.urljoin(target_url, href)
            filename = os.path.basename(urllib.parse.urlparse(full_url).path)
            try:
                filename = urllib.parse.unquote(filename)
            except:
                pass
            
            if not keyword or keyword in filename:
                download_targets.append((filename, full_url))
    
    download_targets = list(set(download_targets))
    if not download_targets:
        return []
    
    downloaded_files = []
    status_text.text(f"{len(download_targets)} ä»¶ã®PDFãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
    
    for i, (filename, url) in enumerate(download_targets):
        try:
            file_res = requests.get(url, headers=headers, timeout=10)
            file_path = os.path.join(save_dir, filename)
            with open(file_path, "wb") as f:
                f.write(file_res.content)
            downloaded_files.append(file_path)
            progress_bar.progress((i + 1) / len(download_targets))
            time.sleep(1)
        except Exception as e:
            st.warning(f"{filename} ã®å–å¾—å¤±æ•—: {e}")
            
    return downloaded_files

# --- é–¢æ•°ï¼šAIã«ã‚ˆã‚‹æŠ½å‡ºï¼ˆã”æŒ‡å®šã®ãƒ¢ãƒ‡ãƒ«åã‚’ä½¿ç”¨ï¼‰ ---
def extract_data_with_ai(pdf_path, filename, debug_mode=False):
    # Gemini 2.5 Flash (Experimental) ã‚’å„ªå…ˆ
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
    except:
        model = genai.GenerativeModel('gemini-flash-latest')

    try:
        sample_file = genai.upload_file(path=pdf_path, display_name=filename)
        while sample_file.state.name == "PROCESSING":
            time.sleep(1)
            sample_file = genai.get_file(sample_file.name)
        
        if sample_file.state.name == "FAILED":
            if debug_mode: st.error("ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return []
            
    except Exception as e:
        if debug_mode: st.error(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return []

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆæŒ‡ç¤ºæ›¸ï¼‰
    prompt = """
    ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿å…¥åŠ›ã®å°‚é–€å®¶ã§ã™ã€‚ã“ã®PDFï¼ˆç”£æ¥­å»ƒæ£„ç‰©å‡¦ç†è¨ˆç”»æ›¸ãƒ»å ±å‘Šæ›¸ï¼‰ã®ã€Œåˆ¥ç´™ã€ã«ã‚ã‚‹è¡¨ã‹ã‚‰ã€æ•°å€¤ã‚’æ­£ç¢ºã«è»¢è¨˜ã—ã¦ãã ã•ã„ã€‚

    ã€æœ€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘
    è¡¨ã«ã¯ã€Œâ‘ ç¾çŠ¶ï¼ˆå‰å¹´åº¦å®Ÿç¸¾ï¼‰ã€ã¨ã€Œâ‘¡è¨ˆç”»ï¼ˆç›®æ¨™ï¼‰ã€ã®2ã¤ã®åˆ—ãŒä¸¦ã‚“ã§ã„ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
    **å¿…ãšã€Œâ‘ ç¾çŠ¶ã€ã¾ãŸã¯ã€Œã€å‰å¹´åº¦å®Ÿç¸¾ã€‘ã€ã¨æ›¸ã‹ã‚Œã¦ã„ã‚‹åˆ—ã®æ•°å€¤ã®ã¿**ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
    ã€Œâ‘¡è¨ˆç”»ã€ã‚„ã€Œã€ç›®æ¨™ã€‘ã€ã®åˆ—ã®æ•°å€¤ã¯çµ¶å¯¾ã«æŠ½å‡ºã—ãªã„ã§ãã ã•ã„ã€‚

    ã€æŠ½å‡ºé …ç›®å®šç¾©ã€‘
    1. **æå‡ºæ—¥**: è¡¨ç´™ã®å³ä¸Šã«ã‚ã‚‹æ—¥ä»˜ï¼ˆä¾‹ï¼šä»¤å’Œ6å¹´5æœˆ21æ—¥ï¼‰ã€‚
    2. **å¯¾è±¡å¹´åº¦**: ã€Œâ‘ ç¾çŠ¶ã€ã‚„ã€Œå®Ÿç¸¾ã€ãŒæŒ‡ã—ã¦ã„ã‚‹å¹´åº¦ã€‚é€šå¸¸ã¯æå‡ºæ—¥ã®å‰å¹´åº¦ï¼ˆä¾‹ï¼šä»¤å’Œ5å¹´åº¦ï¼‰ã€‚
    3. **æ–‡æ›¸ç¨®é¡**: å…¨ã¦ã€Œå ±å‘Šæ›¸ã€ã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    4. **å»ƒæ£„ç‰©ã®ç¨®é¡ã”ã¨ã®è¡Œä½œæˆ**: è¡¨ã«ã‚ã‚‹å…¨ã¦ã®ã€Œç”£æ¥­å»ƒæ£„ç‰©ã®ç¨®é¡ã€ã«ã¤ã„ã¦ã€1ç¨®é¡ã«ã¤ã1ã¤ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆè¡Œï¼‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚åˆè¨ˆè¡Œã¯ä¸è¦ã§ã™ã€‚

    ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
    ä»¥ä¸‹ã®JSONå½¢å¼ã®ãƒªã‚¹ãƒˆï¼ˆé…åˆ—ï¼‰ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚Markdownè¨˜æ³•ï¼ˆ```jsonï¼‰ã¯ä¸è¦ã§ã™ã€‚
    
    [
      {
        "æå‡ºæ—¥": "ä»¤å’Œ6å¹´5æœˆ21æ—¥",
        "å¯¾è±¡å¹´åº¦": "ä»¤å’Œ5å¹´åº¦",
        "æ–‡æ›¸ç¨®é¡": "å ±å‘Šæ›¸",
        "æ’å‡ºäº‹æ¥­è€…å": "æ ªå¼ä¼šç¤¾ã€‡ã€‡",
        "å»ƒæ£„ç‰©ã®ç¨®é¡": "ãŒã‚Œãé¡",
        "â‘©å…¨å‡¦ç†å§”è¨—é‡_ton": 1299.99,
        "â‘ªå„ªè‰¯èªå®šå‡¦ç†æ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡_ton": 0,
        "â‘«å†ç”Ÿåˆ©ç”¨æ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡_ton": 1299.99,
        "â‘¬ç†±å›åèªå®šæ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡_ton": 0,
        "â‘­ç†±å›åèªå®šæ¥­è€…ä»¥å¤–ã®ç†±å›åã‚’è¡Œã†æ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡_ton": 0,
        "è‡ªæ²»ä½“å": "ç¦å²¡å¸‚",
        "å‚™è€ƒ": ""
      }
    ]
    """
    
    try:
        # ç”Ÿæˆå®Ÿè¡Œ
        try:
            model = genai.GenerativeModel('gemini-2.5-flash')
            response = model.generate_content(
                [sample_file, prompt],
                generation_config={"response_mime_type": "application/json"}
            )
        except Exception:
            if debug_mode: st.warning("gemini-2.5-flash ãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€gemini-flash-latest ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            model = genai.GenerativeModel('gemini-flash-latest')
            response = model.generate_content(
                [sample_file, prompt],
                generation_config={"response_mime_type": "application/json"}
            )
        
        if debug_mode:
            st.text(f"--- {filename} ã®AIç”Ÿå›ç­” ---")
            st.text(response.text)

        data_list = json.loads(response.text)
        
        for item in data_list:
            item['ãƒ•ã‚¡ã‚¤ãƒ«å'] = filename
            
        return data_list
    except Exception as e:
        if debug_mode:
            st.error(f"ãƒ‡ãƒ¼ã‚¿è§£æã‚¨ãƒ©ãƒ¼: {e}")
        return []

# --- ãƒ‡ãƒ¼ã‚¿å¤‰æ›é–¢æ•°ï¼ˆExcelç”¨ï¼‰ ---
def convert_df_to_excel(df):
    # ãƒã‚¤ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ä½¿ã†ã¨è¤‡é›‘ã«ãªã‚‹ãŸã‚ã€ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦èª­ã¿è¾¼ã‚€æ–¹å¼
    with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as tmp:
        df.to_excel(tmp.name, index=False)
        with open(tmp.name, "rb") as f:
            data = f.read()
    return data

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
if st.button("ğŸš€ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ & ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚’é–‹å§‹"):
    if not api_key:
        st.error("AIæŠ½å‡ºã‚’è¡Œã†ã«ã¯ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    else:
        status_text = st.empty()
        progress_bar = st.progress(0)

        with tempfile.TemporaryDirectory() as temp_dir:
            save_dir = os.path.join(temp_dir, "pdfs")
            os.makedirs(save_dir, exist_ok=True)
            
            # 1. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            downloaded_files = download_pdfs(target_url, keyword, save_dir, status_text, progress_bar)
            
            if not downloaded_files:
                st.warning("æ¡ä»¶ã«åˆã†PDFãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                status_text.text("AIã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚’é–‹å§‹ã—ã¾ã™...")
                progress_bar.progress(0)
                
                all_extracted_data = []
                
                # 2. AIæŠ½å‡ºãƒ«ãƒ¼ãƒ—
                for i, pdf_path in enumerate(downloaded_files):
                    filename = os.path.basename(pdf_path)
                    status_text.text(f"åˆ†æä¸­ ({i+1}/{len(downloaded_files)}): {filename}")
                    
                    extracted_list = extract_data_with_ai(pdf_path, filename, debug_mode)
                    
                    if extracted_list:
                        all_extracted_data.extend(extracted_list)
                    
                    progress_bar.progress((i + 1) / len(downloaded_files))
                
                # 3. ãƒ‡ãƒ¼ã‚¿æ•´å½¢ã¨ä¿å­˜
                if all_extracted_data:
                    df = pd.DataFrame(all_extracted_data)
                    
                    # åˆ—ã®ä¸¦ã³é †æŒ‡å®š
                    column_mapping = {
                        'ãƒ•ã‚¡ã‚¤ãƒ«å': 'ãƒ•ã‚¡ã‚¤ãƒ«å',
                        'è‡ªæ²»ä½“å': 'è‡ªæ²»ä½“å',
                        'æå‡ºæ—¥': 'æå‡ºæ—¥',
                        'å¯¾è±¡å¹´åº¦': 'å¯¾è±¡å¹´åº¦',
                        'æ–‡æ›¸ç¨®é¡': 'ç¨®é¡',
                        'æ’å‡ºäº‹æ¥­è€…å': 'æ’å‡ºäº‹æ¥­è€…å',
                        'å»ƒæ£„ç‰©ã®ç¨®é¡': 'å»ƒæ£„ç‰©ã®ç¨®é¡',
                        'â‘©å…¨å‡¦ç†å§”è¨—é‡_ton': 'â‘©å…¨å‡¦ç†å§”è¨—é‡(t)',
                        'â‘ªå„ªè‰¯èªå®šå‡¦ç†æ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡_ton': 'â‘ªå„ªè‰¯èªå®š(t)',
                        'â‘«å†ç”Ÿåˆ©ç”¨æ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡_ton': 'â‘«å†ç”Ÿåˆ©ç”¨(t)',
                        'â‘¬ç†±å›åèªå®šæ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡_ton': 'â‘¬ç†±å›åèªå®š(t)',
                        'â‘­ç†±å›åèªå®šæ¥­è€…ä»¥å¤–ã®ç†±å›åã‚’è¡Œã†æ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡_ton': 'â‘­ç†±å›åãã®ä»–(t)',
                        'å‚™è€ƒ': 'å‚™è€ƒ'
                    }
                    
                    target_cols = [c for c in column_mapping.keys() if c in df.columns]
                    df = df[target_cols]
                    df = df.rename(columns=column_mapping)
                    
                    # å±¥æ­´ã«ä¿å­˜
                    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    history_item = {
                        "time": now,
                        "keyword": keyword,
                        "count": len(df),
                        "df": df
                    }
                    st.session_state['history'].append(history_item)
                    
                    st.success(f"ğŸ‰ å‡¦ç†å®Œäº†ï¼ {len(df)} ä»¶ã®å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚")
                else:
                    st.error("ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

# --- å®Ÿè¡Œå±¥æ­´ã‚¨ãƒªã‚¢ ---
st.markdown("---")
st.subheader("ğŸ“‚ å®Ÿè¡Œå±¥æ­´")

if len(st.session_state['history']) == 0:
    st.write("å±¥æ­´ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
else:
    # ---------------------------------------------------------
    # ã€è¿½åŠ æ©Ÿèƒ½ã€‘å±¥æ­´ãŒè¤‡æ•°ã‚ã‚‹å ´åˆã€ã¾ã¨ã‚ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
    # ---------------------------------------------------------
    if len(st.session_state['history']) > 1:
        st.info("ğŸ’¡ è¤‡æ•°ã®æŠ½å‡ºçµæœãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚‰ã‚’1ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¾ã¨ã‚ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")
        
        # å…¨ã¦ã®DataFrameã‚’çµåˆ (pd.concat)
        all_dfs = [item['df'] for item in st.session_state['history']]
        merged_df = pd.concat(all_dfs, ignore_index=True)
        
        # çµåˆãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        merged_excel = convert_df_to_excel(merged_df)
        now_str = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        
        st.download_button(
            label="ğŸ“¦ å±¥æ­´ã‚’ã™ã¹ã¦çµåˆã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (Merge All)",
            data=merged_excel,
            file_name=f"waste_report_merged_{now_str}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="download_all_btn"
        )
        st.markdown("---")

    # å€‹åˆ¥ã®å±¥æ­´è¡¨ç¤º
    for i, item in enumerate(reversed(st.session_state['history'])):
        with st.expander(f"ã€{item['time']}ã€‘ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {item['keyword']} (æŠ½å‡ºæ•°: {item['count']}ä»¶)"):
            st.dataframe(item['df'])
            
            # Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            excel_data = convert_df_to_excel(item['df'])
            st.download_button(
                label=f"ğŸ“¥ ã“ã®Excelã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=excel_data,
                file_name=f"waste_report_{item['time'].replace(':','-')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key=f"dl_btn_{i}"
            )
        
