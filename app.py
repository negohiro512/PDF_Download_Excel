import streamlit as st
import os
import time
import urllib.parse
import requests
import shutil
import tempfile
import json
import pandas as pd
from bs4 import BeautifulSoup
import google.generativeai as genai

# --- ç”»é¢è¨­å®š ---
st.set_page_config(page_title="PDFä¸€æ‹¬DL & AIæŠ½å‡º", layout="wide")

st.title("ğŸ“„ PDFä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼ & AIå°å¸³ä½œæˆ")
st.markdown("""
æŒ‡å®šã—ãŸURLã‹ã‚‰PDFã‚’åé›†ã—ã€**AI (Gemini)** ã‚’ä½¿ã£ã¦ä¸­èº«ã‚’è‡ªå‹•ã§èª­ã¿å–ã‚Šã€
æŒ‡å®šã®é …ç›®ã‚’Excelä¸€è¦§è¡¨ã«ã—ã¦å‡ºåŠ›ã—ã¾ã™ã€‚
""")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šè¨­å®š ---
with st.sidebar:
    st.header("è¨­å®š")
    api_key = st.text_input("Gemini APIã‚­ãƒ¼", type="password", help="Google AI Studioã§å–å¾—ã—ãŸã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    if api_key:
        genai.configure(api_key=api_key)
    
    st.info("â€»APIã‚­ãƒ¼ãŒãªã„å ´åˆã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã®ã¿å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚")

# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›æ¬„ ---
col1, col2 = st.columns([2, 1])
with col1:
    default_url = "https://www.city.fukuoka.lg.jp/kankyo/sanhai/hp/sangyouhaikibutu/haisyutujigyousya/taryoukouhyou.html"
    target_url = st.text_input("å¯¾è±¡ã®URL", default_url)
with col2:
    keyword = st.text_input("ãƒ•ã‚¡ã‚¤ãƒ«åã«å«ã‚€æ–‡å­—", "06")

# --- é–¢æ•°ï¼šPDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆä¿®æ­£ç‰ˆï¼‰ ---
def download_pdfs(target_url, keyword, save_dir, status_text, progress_bar):
    # ã€ä¿®æ­£1ã€‘ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å¼·åŒ–ã—ã¦ã€æ™®é€šã®ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ã«è¦‹ã›ã‹ã‘ã‚‹
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
        "Accept-Language": "ja,en-US;q=0.9,en;q=0.8",  # æ—¥æœ¬èªç’°å¢ƒã§ã‚ã‚‹ã“ã¨ã‚’ä¼ãˆã‚‹
        "Referer": "https://www.google.com/"             # Googleæ¤œç´¢ã‹ã‚‰æ¥ãŸãµã‚Šã‚’ã™ã‚‹
    }
    
    status_text.text("ã‚µã‚¤ãƒˆã®æƒ…å ±ã‚’å–å¾—ä¸­...")
    
    try:
        # ã€ä¿®æ­£2ã€‘ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šã‚’è¿½åŠ ï¼ˆãšã£ã¨å¾…æ©Ÿã—ã¦ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã®ã‚’é˜²ãï¼‰
        response = requests.get(target_url, headers=headers, timeout=10)
        response.raise_for_status()
    except requests.exceptions.HTTPError as e:
        # å…·ä½“çš„ãªã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ï¼ˆ403ã‚„404ãªã©ï¼‰ã‚’è¡¨ç¤ºã™ã‚‹
        st.error(f"ã‚µã‚¤ãƒˆã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: {e.response.status_code}")
        st.write("è€ƒãˆã‚‰ã‚Œã‚‹åŸå› : Streamlit Cloudã®ã‚µãƒ¼ãƒãƒ¼ï¼ˆæµ·å¤–IPï¼‰ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        return []
    except Exception as e:
        st.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return []
    
    # --- ä»¥ä¸‹ã¯å¤‰æ›´ãªã—ï¼ˆæ–‡å­—åŒ–ã‘å¯¾ç­–ã‚’è¿½åŠ ã—ã¦å®‰å®šã•ã›ã¦ã„ã¾ã™ï¼‰ ---
    response.encoding = response.apparent_encoding  # æ–‡å­—åŒ–ã‘é˜²æ­¢
    soup = BeautifulSoup(response.content, "html.parser")
    links = soup.find_all("a")
    
    download_targets = []
    for link in links:
        href = link.get("href")
        if href and href.lower().endswith(".pdf"):
            full_url = urllib.parse.urljoin(target_url, href)
            filename = os.path.basename(urllib.parse.urlparse(full_url).path)
            try:
                filename = urllib.parse.unquote(filename)
            except:
                pass
            
            if not keyword or keyword in filename:
                download_targets.append((filename, full_url))
    
    download_targets = list(set(download_targets))
    
    if not download_targets:
        return []
    
    downloaded_files = []
    status_text.text(f"{len(download_targets)} ä»¶ã®PDFãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
    
    for i, (filename, url) in enumerate(download_targets):
        try:
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ™‚ã‚‚åŒã˜ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ä½¿ã†
            file_res = requests.get(url, headers=headers, timeout=10)
            file_path = os.path.join(save_dir, filename)
            with open(file_path, "wb") as f:
                f.write(file_res.content)
            downloaded_files.append(file_path)
            
            progress_bar.progress((i + 1) / len(download_targets))
            time.sleep(1) # ã€ä¿®æ­£3ã€‘ã‚¢ã‚¯ã‚»ã‚¹é–“éš”ã‚’å°‘ã—é•·ã‚ã«ï¼ˆ1ç§’ï¼‰ã—ã¦ãƒ–ãƒ­ãƒƒã‚¯ã‚’é˜²ã
        except Exception as e:
            st.warning(f"{filename} ã®å–å¾—å¤±æ•—: {e}")
            
    return downloaded_files

# --- é–¢æ•°ï¼šAIã«ã‚ˆã‚‹æŠ½å‡º ---
def extract_data_with_ai(pdf_path, filename):
    # Gemini 2.5 Flashãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼ˆé«˜é€Ÿãƒ»å®‰ä¾¡ï¼‰
    model = genai.GenerativeModel('gemini-2.5-flash')
    
    # PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    sample_file = genai.upload_file(path=pdf_path, display_name=filename)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†å®Œäº†ã‚’å¾…æ©Ÿ
    while sample_file.state.name == "PROCESSING":
        time.sleep(1)
        sample_file = genai.get_file(sample_file.name)
        
    if sample_file.state.name == "FAILED":
        return None

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆæŒ‡ç¤ºæ›¸ï¼‰
    prompt = """
    ã“ã®PDFã¯ç”£æ¥­å»ƒæ£„ç‰©ã®å‡¦ç†è¨ˆç”»æ›¸ã¾ãŸã¯å ±å‘Šæ›¸ã§ã™ã€‚
    ä»¥ä¸‹ã®é …ç›®ã‚’æŠ½å‡ºã—ã€JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    å€¤ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ null ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚
    
    ã€æŠ½å‡ºé …ç›®ã€‘
    - å¯¾è±¡å¹´åº¦: æ–‡æ›¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚„å¯¾è±¡æœŸé–“ã‹ã‚‰ã€ã“ã®å ±å‘ŠãŒã€Œä½•å¹´åº¦ã€ã®ã‚‚ã®ã‹æŠ½å‡ºï¼ˆä¾‹ï¼šã€Œä»¤å’Œ6å¹´åº¦ã€ã€Œ2024å¹´åº¦ã€ï¼‰ã€‚ä¸æ˜ãªå ´åˆã¯æ—¥ä»˜ã‚’è¨˜è¼‰ã€‚
    - æ–‡æ›¸ç¨®é¡: æ–‡æ›¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã«åŸºã¥ãã€ã€Œè¨ˆç”»æ›¸ã€ã¾ãŸã¯ã€Œå ±å‘Šæ›¸ã€ã®ã„ãšã‚Œã‹ã‚’å‡ºåŠ›ã€‚ã€Œå‡¦ç†è¨ˆç”»æ›¸ã€ãªã‚‰ã€Œè¨ˆç”»æ›¸ã€ã€ã€Œå®Ÿæ–½çŠ¶æ³å ±å‘Šæ›¸ã€ãªã‚‰ã€Œå ±å‘Šæ›¸ã€ã¨çŸ­ãè¨˜è¼‰ã™ã‚‹ã“ã¨ã€‚
    - è‡ªæ²»ä½“å(çœŒ): æ–‡æ›¸å†…ã®æå‡ºå…ˆã‚„ä½æ‰€ã‹ã‚‰éƒ½é“åºœçœŒåã‚’æ¨æ¸¬ã¾ãŸã¯æŠ½å‡º
    - è‡ªæ²»ä½“å: æ–‡æ›¸å†…ã®æå‡ºå…ˆã‹ã‚‰å¸‚ç”ºæ‘åã‚’æŠ½å‡ºï¼ˆä¾‹ï¼šç¦å²¡å¸‚é•·æ®¿ãªã‚‰ç¦å²¡å¸‚ï¼‰
    - äº‹æ¥­ã®ç¨®é¡: äº‹æ¥­ã®å†…å®¹ã‚„æ¥­ç¨®
    - æ’å‡ºäº‹æ¥­è€…å: ä¼šç¤¾åã€æ°åã€ã¾ãŸã¯æå‡ºè€…å
    - äº‹æ¥­å ´å: å·¥å ´åã‚„äº‹æ¥­æ‰€åï¼ˆãªã‘ã‚Œã°ã€ŒåŒä¸Šã€ãªã©è¨˜è¼‰é€šã‚Šã«ï¼‰
    - ä½æ‰€: äº‹æ¥­å ´ã®æ‰€åœ¨åœ°
    - ç”£æ¥­å»ƒæ£„ç‰©ã®ç¨®é¡: è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ä¸»ãªå»ƒæ£„ç‰©ã®ç¨®é¡ï¼ˆè¤‡æ•°ã‚ã‚‹å ´åˆã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰
    - å…¨å‡¦ç†å§”è¨—é‡_ton: ã€Œâ‘©å…¨å‡¦ç†å§”è¨—é‡ã€ã«ç›¸å½“ã™ã‚‹æ•°å€¤
    - å„ªè‰¯èªå®šå‡¦ç†æ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡_ton: ã€Œâ‘ªå„ªè‰¯èªå®šå‡¦ç†æ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡ã€ã«ç›¸å½“ã™ã‚‹æ•°å€¤
    - å†ç”Ÿåˆ©ç”¨æ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡_ton: ã€Œâ‘«å†ç”Ÿåˆ©ç”¨æ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡ã€ã«ç›¸å½“ã™ã‚‹æ•°å€¤
    - ç†±å›åèªå®šæ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡_ton: ã€Œâ‘¬ç†±å›åèªå®šæ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡ã€ã«ç›¸å½“ã™ã‚‹æ•°å€¤
    - ç†±å›åèªå®šæ¥­è€…ä»¥å¤–ã®ç†±å›åã‚’è¡Œã†æ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡_ton: ã€Œâ‘­ç†±å›åèªå®šæ¥­è€…ä»¥å¤–ã®ç†±å›åã‚’è¡Œã†æ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡ã€ã«ç›¸å½“ã™ã‚‹æ•°å€¤
    - å‚™è€ƒ: ç‰¹è¨˜äº‹é …ãŒã‚ã‚Œã°
    """
    
    # JSONå½¢å¼ã§ã®å›ç­”ã‚’å¼·åˆ¶
    response = model.generate_content(
        [sample_file, prompt],
        generation_config={"response_mime_type": "application/json"}
    )
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’è§£æã—ã¦è¾æ›¸å‹ã§è¿”ã™
    try:
        data = json.loads(response.text)
        data['ãƒ•ã‚¡ã‚¤ãƒ«å'] = filename # ãƒ•ã‚¡ã‚¤ãƒ«åã‚‚ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
        return data
    except:
        return None

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
if st.button("ğŸš€ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ & ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚’é–‹å§‹"):
    if not api_key:
        st.error("AIæŠ½å‡ºã‚’è¡Œã†ã«ã¯ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    else:
        # è¡¨ç¤ºç”¨ã‚³ãƒ³ãƒ†ãƒŠ
        status_text = st.empty()
        progress_bar = st.progress(0)
        result_area = st.container()

        with tempfile.TemporaryDirectory() as temp_dir:
            save_dir = os.path.join(temp_dir, "pdfs")
            os.makedirs(save_dir, exist_ok=True)
            
            # 1. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
            downloaded_files = download_pdfs(target_url, keyword, save_dir, status_text, progress_bar)
            
            if not downloaded_files:
                st.warning("æ¡ä»¶ã«åˆã†PDFãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                status_text.text("AIã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚’é–‹å§‹ã—ã¾ã™...ï¼ˆã“ã‚Œã«ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰")
                progress_bar.progress(0)
                
                extracted_data_list = []
                
                # 2. AIæŠ½å‡ºãƒ«ãƒ¼ãƒ—
                for i, pdf_path in enumerate(downloaded_files):
                    filename = os.path.basename(pdf_path)
                    status_text.text(f"åˆ†æä¸­ ({i+1}/{len(downloaded_files)}): {filename}")
                    
                    try:
                        data = extract_data_with_ai(pdf_path, filename)
                        if data:
                            extracted_data_list.append(data)
                    except Exception as e:
                        st.error(f"{filename} ã®AIè§£æã§ã‚¨ãƒ©ãƒ¼: {e}")
                    
                    progress_bar.progress((i + 1) / len(downloaded_files))
                
                # 3. ãƒ‡ãƒ¼ã‚¿æ•´å½¢ã¨ExcelåŒ–
                if extracted_data_list:
                    df = pd.DataFrame(extracted_data_list)
                    
                    # ã‚«ãƒ©ãƒ ã®ä¸¦ã³æ›¿ãˆã¨æ—¥æœ¬èªãƒªãƒãƒ¼ãƒ 
                    column_mapping = {
                        'ãƒ•ã‚¡ã‚¤ãƒ«å': 'ãƒ•ã‚¡ã‚¤ãƒ«å',
                        'å¯¾è±¡å¹´åº¦': 'å¯¾è±¡å¹´åº¦',
                        'æ–‡æ›¸ç¨®é¡': 'ç¨®é¡',        # ã€è¿½åŠ ã€‘ã“ã“ã«è¨ˆç”»æ›¸/å ±å‘Šæ›¸ãŒå…¥ã‚Šã¾ã™
                        'è‡ªæ²»ä½“å(çœŒ)': 'è‡ªæ²»ä½“å(çœŒ)',
                        'è‡ªæ²»ä½“å': 'è‡ªæ²»ä½“å',
                        'äº‹æ¥­ã®ç¨®é¡': 'äº‹æ¥­ã®ç¨®é¡',
                        'æ’å‡ºäº‹æ¥­è€…å': 'æ’å‡ºäº‹æ¥­è€…åï¼ˆï¼ä¼šç¤¾åï¼‰',
                        'äº‹æ¥­å ´å': 'äº‹æ¥­å ´åï¼ˆï¼å·¥å ´åoräº‹æ¥­æ‰€åï¼‰',
                        'ä½æ‰€': 'ä½æ‰€',
                        'ç”£æ¥­å»ƒæ£„ç‰©ã®ç¨®é¡': 'ç”£æ¥­å»ƒæ£„ç‰©ã®ç¨®é¡',
                        'å…¨å‡¦ç†å§”è¨—é‡_ton': 'â‘©å…¨å‡¦ç†å§”è¨—é‡ï¼ˆtonï¼‰',
                        'å„ªè‰¯èªå®šå‡¦ç†æ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡_ton': 'â‘ªå„ªè‰¯èªå®šå‡¦ç†æ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡ï¼ˆtonï¼‰',
                        'å†ç”Ÿåˆ©ç”¨æ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡_ton': 'â‘«å†ç”Ÿåˆ©ç”¨æ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡ï¼ˆtonï¼‰',
                        'ç†±å›åèªå®šæ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡_ton': 'â‘¬ç†±å›åèªå®šæ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡ï¼ˆtonï¼‰',
                        'ç†±å›åèªå®šæ¥­è€…ä»¥å¤–ã®ç†±å›åã‚’è¡Œã†æ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡_ton': 'â‘­ç†±å›åèªå®šæ¥­è€…ä»¥å¤–ã®ç†±å›åã‚’è¡Œã†æ¥­è€…ã¸ã®å‡¦ç†å§”è¨—é‡ï¼ˆtonï¼‰',
                        'å‚™è€ƒ': 'å‚™è€ƒ'
                    }
                    
                    # å­˜åœ¨ã—ãªã„ã‚«ãƒ©ãƒ ã¯ç„¡è¦–ã—ã¦ãƒªãƒãƒ¼ãƒ 
                    df = df.rename(columns=column_mapping)
                    
                    # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šã®é †ç•ªã«ä¸¦ã¹æ›¿ãˆ
                    target_columns = list(column_mapping.values())
                    existing_cols = [c for c in target_columns if c in df.columns]
                    df = df[existing_cols]

                    # çµæœè¡¨ç¤º
                    st.success("ğŸ‰ å…¨ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                    st.dataframe(df)
                    
                    # Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                    excel_path = os.path.join(temp_dir, "summary_list.xlsx")
                    df.to_excel(excel_path, index=False)
                    
                    with open(excel_path, "rb") as f:
                        st.download_button(
                            label="ğŸ“¥ Excelä¸€è¦§è¡¨ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=f,
                            file_name="waste_report_summary.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                else:
                    st.error("ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
